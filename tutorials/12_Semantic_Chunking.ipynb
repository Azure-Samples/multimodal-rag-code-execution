{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approach Overview\n",
    "\n",
    "Two chunking methods combined:\n",
    "\n",
    " 1. Splitting by the markdown headers. Expecting the input to be pre-processed by document intelligence (or other tools).\n",
    " 2. If chunks exceed MAX_CHUNK_TOKEN_SIZE, split further by using semantic chunker.\n",
    " 3. If the resulting semantic chunk is still larger than MAX_CHUNK_TOKEN_SIZE, use Semantic Chunking on this chunk alone. \n",
    " No recursion, just put it back into queue .\n",
    "\n",
    "\n",
    "Using Langchain splitters. Also included Llama Index Semantic Chunker as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tiktoken in /opt/miniconda3/envs/C1/lib/python3.11/site-packages (0.6.0)\n",
      "Requirement already satisfied: langchain_experimental in /opt/miniconda3/envs/C1/lib/python3.11/site-packages (0.0.56)\n",
      "Requirement already satisfied: langchain_openai in /opt/miniconda3/envs/C1/lib/python3.11/site-packages (0.1.1)\n",
      "Requirement already satisfied: langchain-text-splitters in /opt/miniconda3/envs/C1/lib/python3.11/site-packages (0.0.1)\n",
      "Requirement already satisfied: python-dotenv in /opt/miniconda3/envs/C1/lib/python3.11/site-packages (1.0.1)\n",
      "Requirement already satisfied: llama-index in /opt/miniconda3/envs/C1/lib/python3.11/site-packages (0.10.23)\n",
      "Requirement already satisfied: llama-index-embeddings-azure-openai in /opt/miniconda3/envs/C1/lib/python3.11/site-packages (0.1.6)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /opt/miniconda3/envs/C1/lib/python3.11/site-packages (from tiktoken) (2023.12.25)\n",
      "Requirement already satisfied: requests>=2.26.0 in /opt/miniconda3/envs/C1/lib/python3.11/site-packages (from tiktoken) (2.31.0)\n",
      "Requirement already satisfied: langchain<0.2.0,>=0.1.14 in /opt/miniconda3/envs/C1/lib/python3.11/site-packages (from langchain_experimental) (0.1.14)\n",
      "Requirement already satisfied: langchain-core<0.2.0,>=0.1.37 in /opt/miniconda3/envs/C1/lib/python3.11/site-packages (from langchain_experimental) (0.1.37)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.10.0 in /opt/miniconda3/envs/C1/lib/python3.11/site-packages (from langchain_openai) (1.14.1)\n",
      "Requirement already satisfied: llama-index-agent-openai<0.2.0,>=0.1.4 in /opt/miniconda3/envs/C1/lib/python3.11/site-packages (from llama-index) (0.1.7)\n",
      "Requirement already satisfied: llama-index-cli<0.2.0,>=0.1.2 in /opt/miniconda3/envs/C1/lib/python3.11/site-packages (from llama-index) (0.1.11)\n",
      "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.23 in /opt/miniconda3/envs/C1/lib/python3.11/site-packages (from llama-index) (0.10.23.post1)\n",
      "Requirement already satisfied: llama-index-embeddings-openai<0.2.0,>=0.1.5 in /opt/miniconda3/envs/C1/lib/python3.11/site-packages (from llama-index) (0.1.7)\n",
      "Requirement already satisfied: llama-index-indices-managed-llama-cloud<0.2.0,>=0.1.2 in /opt/miniconda3/envs/C1/lib/python3.11/site-packages (from llama-index) (0.1.5)\n",
      "Requirement already satisfied: llama-index-legacy<0.10.0,>=0.9.48 in /opt/miniconda3/envs/C1/lib/python3.11/site-packages (from llama-index) (0.9.48)\n",
      "Requirement already satisfied: llama-index-llms-openai<0.2.0,>=0.1.5 in /opt/miniconda3/envs/C1/lib/python3.11/site-packages (from llama-index) (0.1.12)\n",
      "Requirement already satisfied: llama-index-multi-modal-llms-openai<0.2.0,>=0.1.3 in /opt/miniconda3/envs/C1/lib/python3.11/site-packages (from llama-index) (0.1.4)\n",
      "Requirement already satisfied: llama-index-program-openai<0.2.0,>=0.1.3 in /opt/miniconda3/envs/C1/lib/python3.11/site-packages (from llama-index) (0.1.4)\n",
      "Requirement already satisfied: llama-index-question-gen-openai<0.2.0,>=0.1.2 in /opt/miniconda3/envs/C1/lib/python3.11/site-packages (from llama-index) (0.1.3)\n",
      "Requirement already satisfied: llama-index-readers-file<0.2.0,>=0.1.4 in /opt/miniconda3/envs/C1/lib/python3.11/site-packages (from llama-index) (0.1.12)\n",
      "Requirement already satisfied: llama-index-readers-llama-parse<0.2.0,>=0.1.2 in /opt/miniconda3/envs/C1/lib/python3.11/site-packages (from llama-index) (0.1.3)\n",
      "Requirement already satisfied: llama-index-llms-azure-openai<0.2.0,>=0.1.3 in /opt/miniconda3/envs/C1/lib/python3.11/site-packages (from llama-index-embeddings-azure-openai) (0.1.5)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/miniconda3/envs/C1/lib/python3.11/site-packages (from langchain<0.2.0,>=0.1.14->langchain_experimental) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/miniconda3/envs/C1/lib/python3.11/site-packages (from langchain<0.2.0,>=0.1.14->langchain_experimental) (2.0.28)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/miniconda3/envs/C1/lib/python3.11/site-packages (from langchain<0.2.0,>=0.1.14->langchain_experimental) (3.9.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/miniconda3/envs/C1/lib/python3.11/site-packages (from langchain<0.2.0,>=0.1.14->langchain_experimental) (0.6.4)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/miniconda3/envs/C1/lib/python3.11/site-packages (from langchain<0.2.0,>=0.1.14->langchain_experimental) (1.33)\n",
      "Requirement already satisfied: langchain-community<0.1,>=0.0.30 in /opt/miniconda3/envs/C1/lib/python3.11/site-packages (from langchain<0.2.0,>=0.1.14->langchain_experimental) (0.0.30)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /opt/miniconda3/envs/C1/lib/python3.11/site-packages (from langchain<0.2.0,>=0.1.14->langchain_experimental) (0.1.38)\n",
      "Requirement already satisfied: numpy<2,>=1 in /opt/miniconda3/envs/C1/lib/python3.11/site-packages (from langchain<0.2.0,>=0.1.14->langchain_experimental) (1.23.5)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /opt/miniconda3/envs/C1/lib/python3.11/site-packages (from langchain<0.2.0,>=0.1.14->langchain_experimental) (2.6.4)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /opt/miniconda3/envs/C1/lib/python3.11/site-packages (from langchain<0.2.0,>=0.1.14->langchain_experimental) (8.2.3)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in /opt/miniconda3/envs/C1/lib/python3.11/site-packages (from langchain-core<0.2.0,>=0.1.37->langchain_experimental) (23.2)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /opt/miniconda3/envs/C1/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.23->llama-index) (1.2.14)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /opt/miniconda3/envs/C1/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.23->llama-index) (1.0.8)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/miniconda3/envs/C1/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.23->llama-index) (2024.3.0)\n",
      "Requirement already satisfied: httpx in /opt/miniconda3/envs/C1/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.23->llama-index) (0.26.0)\n",
      "Requirement already satisfied: llamaindex-py-client<0.2.0,>=0.1.13 in /opt/miniconda3/envs/C1/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.23->llama-index) (0.1.13)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /opt/miniconda3/envs/C1/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.23->llama-index) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /opt/miniconda3/envs/C1/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.23->llama-index) (3.2.1)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /opt/miniconda3/envs/C1/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.23->llama-index) (3.8.1)\n",
      "Requirement already satisfied: pandas in /opt/miniconda3/envs/C1/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.23->llama-index) (2.2.1)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /opt/miniconda3/envs/C1/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.23->llama-index) (10.2.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /opt/miniconda3/envs/C1/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.23->llama-index) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /opt/miniconda3/envs/C1/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.23->llama-index) (4.9.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /opt/miniconda3/envs/C1/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.23->llama-index) (0.9.0)\n",
      "Requirement already satisfied: azure-identity<2.0.0,>=1.15.0 in /opt/miniconda3/envs/C1/lib/python3.11/site-packages (from llama-index-llms-azure-openai<0.2.0,>=0.1.3->llama-index-embeddings-azure-openai) (1.15.0)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /opt/miniconda3/envs/C1/lib/python3.11/site-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (4.12.3)\n",
      "Requirement already satisfied: bs4<0.0.3,>=0.0.2 in /opt/miniconda3/envs/C1/lib/python3.11/site-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (0.0.2)\n",
      "Requirement already satisfied: pymupdf<2.0.0,>=1.23.21 in /opt/miniconda3/envs/C1/lib/python3.11/site-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (1.23.26)\n",
      "Requirement already satisfied: pypdf<5.0.0,>=4.0.1 in /opt/miniconda3/envs/C1/lib/python3.11/site-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (4.1.0)\n",
      "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in /opt/miniconda3/envs/C1/lib/python3.11/site-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (0.0.26)\n",
      "Requirement already satisfied: llama-parse<0.4.0,>=0.3.3 in /opt/miniconda3/envs/C1/lib/python3.11/site-packages (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index) (0.3.9)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/miniconda3/envs/C1/lib/python3.11/site-packages (from openai<2.0.0,>=1.10.0->langchain_openai) (3.7.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/miniconda3/envs/C1/lib/python3.11/site-packages (from openai<2.0.0,>=1.10.0->langchain_openai) (1.9.0)\n",
      "Requirement already satisfied: sniffio in /opt/miniconda3/envs/C1/lib/python3.11/site-packages (from openai<2.0.0,>=1.10.0->langchain_openai) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/miniconda3/envs/C1/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/miniconda3/envs/C1/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/miniconda3/envs/C1/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/miniconda3/envs/C1/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken) (2024.2.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/miniconda3/envs/C1/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2.0,>=0.1.14->langchain_experimental) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/miniconda3/envs/C1/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2.0,>=0.1.14->langchain_experimental) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/miniconda3/envs/C1/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2.0,>=0.1.14->langchain_experimental) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/miniconda3/envs/C1/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2.0,>=0.1.14->langchain_experimental) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/miniconda3/envs/C1/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2.0,>=0.1.14->langchain_experimental) (1.9.4)\n",
      "Requirement already satisfied: azure-core<2.0.0,>=1.23.0 in /opt/miniconda3/envs/C1/lib/python3.11/site-packages (from azure-identity<2.0.0,>=1.15.0->llama-index-llms-azure-openai<0.2.0,>=0.1.3->llama-index-embeddings-azure-openai) (1.30.1)\n",
      "Requirement already satisfied: cryptography>=2.5 in /opt/miniconda3/envs/C1/lib/python3.11/site-packages (from azure-identity<2.0.0,>=1.15.0->llama-index-llms-azure-openai<0.2.0,>=0.1.3->llama-index-embeddings-azure-openai) (42.0.5)\n",
      "Requirement already satisfied: msal<2.0.0,>=1.24.0 in /opt/miniconda3/envs/C1/lib/python3.11/site-packages (from azure-identity<2.0.0,>=1.15.0->llama-index-llms-azure-openai<0.2.0,>=0.1.3->llama-index-embeddings-azure-openai) (1.28.0)\n",
      "Requirement already satisfied: msal-extensions<2.0.0,>=0.3.0 in /opt/miniconda3/envs/C1/lib/python3.11/site-packages (from azure-identity<2.0.0,>=1.15.0->llama-index-llms-azure-openai<0.2.0,>=0.1.3->llama-index-embeddings-azure-openai) (1.1.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/miniconda3/envs/C1/lib/python3.11/site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (2.5)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/miniconda3/envs/C1/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain<0.2.0,>=0.1.14->langchain_experimental) (3.20.2)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /opt/miniconda3/envs/C1/lib/python3.11/site-packages (from deprecated>=1.2.9.3->llama-index-core<0.11.0,>=0.10.23->llama-index) (1.14.1)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/miniconda3/envs/C1/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.23->llama-index) (1.0.4)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/miniconda3/envs/C1/lib/python3.11/site-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.23->llama-index) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/miniconda3/envs/C1/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain<0.2.0,>=0.1.14->langchain_experimental) (2.4)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/miniconda3/envs/C1/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.17->langchain<0.2.0,>=0.1.14->langchain_experimental) (3.9.15)\n",
      "Requirement already satisfied: click in /opt/miniconda3/envs/C1/lib/python3.11/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.23->llama-index) (8.1.7)\n",
      "Requirement already satisfied: joblib in /opt/miniconda3/envs/C1/lib/python3.11/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.23->llama-index) (1.3.2)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/miniconda3/envs/C1/lib/python3.11/site-packages (from pydantic<3,>=1->langchain<0.2.0,>=0.1.14->langchain_experimental) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in /opt/miniconda3/envs/C1/lib/python3.11/site-packages (from pydantic<3,>=1->langchain<0.2.0,>=0.1.14->langchain_experimental) (2.16.3)\n",
      "Requirement already satisfied: PyMuPDFb==1.23.22 in /opt/miniconda3/envs/C1/lib/python3.11/site-packages (from pymupdf<2.0.0,>=1.23.21->llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (1.23.22)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/miniconda3/envs/C1/lib/python3.11/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.23->llama-index) (3.0.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/miniconda3/envs/C1/lib/python3.11/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.23->llama-index) (1.0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/miniconda3/envs/C1/lib/python3.11/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.23->llama-index) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/miniconda3/envs/C1/lib/python3.11/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.23->llama-index) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/miniconda3/envs/C1/lib/python3.11/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.23->llama-index) (2024.1)\n",
      "Requirement already satisfied: six>=1.11.0 in /opt/miniconda3/envs/C1/lib/python3.11/site-packages (from azure-core<2.0.0,>=1.23.0->azure-identity<2.0.0,>=1.15.0->llama-index-llms-azure-openai<0.2.0,>=0.1.3->llama-index-embeddings-azure-openai) (1.16.0)\n",
      "Requirement already satisfied: cffi>=1.12 in /opt/miniconda3/envs/C1/lib/python3.11/site-packages (from cryptography>=2.5->azure-identity<2.0.0,>=1.15.0->llama-index-llms-azure-openai<0.2.0,>=0.1.3->llama-index-embeddings-azure-openai) (1.16.0)\n",
      "Requirement already satisfied: PyJWT<3,>=1.0.0 in /opt/miniconda3/envs/C1/lib/python3.11/site-packages (from PyJWT[crypto]<3,>=1.0.0->msal<2.0.0,>=1.24.0->azure-identity<2.0.0,>=1.15.0->llama-index-llms-azure-openai<0.2.0,>=0.1.3->llama-index-embeddings-azure-openai) (2.8.0)\n",
      "Requirement already satisfied: portalocker<3,>=1.0 in /opt/miniconda3/envs/C1/lib/python3.11/site-packages (from msal-extensions<2.0.0,>=0.3.0->azure-identity<2.0.0,>=1.15.0->llama-index-llms-azure-openai<0.2.0,>=0.1.3->llama-index-embeddings-azure-openai) (2.8.2)\n",
      "Requirement already satisfied: pycparser in /opt/miniconda3/envs/C1/lib/python3.11/site-packages (from cffi>=1.12->cryptography>=2.5->azure-identity<2.0.0,>=1.15.0->llama-index-llms-azure-openai<0.2.0,>=0.1.3->llama-index-embeddings-azure-openai) (2.21)\n"
     ]
    }
   ],
   "source": [
    "!pip install tiktoken langchain_experimental langchain_openai langchain-text-splitters python-dotenv llama-index llama-index-embeddings-azure-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain.text_splitter import MarkdownHeaderTextSplitter\n",
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "from langchain_openai.embeddings import AzureOpenAIEmbeddings\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "\n",
    "MAX_CHUNK_TOKEN_SIZE = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [ SEMANTIC SPLITTER ]\n",
    "embeddings = AzureOpenAIEmbeddings(\n",
    "    azure_deployment = os.environ[\"AZURE_OPENAI_EMBEDDING_MODEL\"],\n",
    "    azure_endpoint = os.environ[\"AZURE_OPENAI_ENDPOINT\"],\n",
    "    openai_api_key = os.environ[\"AZURE_OPENAI_API_KEY\"],\n",
    "    openai_api_version = \"2024-02-01\"\n",
    ")\n",
    "\n",
    "# Uses cosine similarity to determine the semantic similarity between two chunks. \n",
    "# If the similarity is below the threshold, the sentences will be merged itno the same chunk.\n",
    "# Otherwise - starting a new chunk\n",
    "semantic_splitter = SemanticChunker(embeddings, breakpoint_threshold_type=\"percentile\", breakpoint_threshold_amount=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [ MARKDOWN SPLITTER ] \n",
    "# The second value (like \"header+1\") becomes a key in the metadata output from the splitter\n",
    "headers_to_split_on = [\n",
    "    (\"#\", \"header_1\"),\n",
    "    (\"##\", \"header_2\"),\n",
    "    (\"###\", \"header_3\"),\n",
    "]\n",
    "markdown_splitter = MarkdownHeaderTextSplitter(headers_to_split_on=headers_to_split_on, strip_headers = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_len(input: str) -> int:\n",
    "    \"\"\"Returns number of tokens for the input. Only for models > gpt-3.5 supported as we use 'cl100k_base' encoding.\"\"\"\n",
    "    encoding = tiktoken.get_encoding(\"cl100k_base\") \n",
    "    return len(encoding.encode(input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_semantic_split(pages):\n",
    "    queue = deque(s for s in pages)  # Initialize queue \n",
    "    result = []\n",
    "\n",
    "    while queue:\n",
    "        current_page = queue.popleft()\n",
    "        # If the chunk is too large, semantically split it into smaller chunks and add them back to the queue, to check if they fit the token limit\n",
    "        if token_len(current_page) > MAX_CHUNK_TOKEN_SIZE:\n",
    "            semantic_chunks = semantic_splitter.split_text(current_page)\n",
    "            for s_chunk in reversed(semantic_chunks):\n",
    "                queue.appendleft(s_chunk) \n",
    "        else:\n",
    "            result.append(current_page)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [ TEST ] \n",
    "# Reading source document\n",
    "# Normally would be expecting here a markdown document, but for the sake of the example we are using a plain text\n",
    "with open(\"./sample_data/Tesla_Model_S.txt\") as f:\n",
    "    input_text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Markdown split \n",
    "md_header_splits = markdown_splitter.split_text(input_text)\n",
    "plain_content = [ value.page_content for value in md_header_splits] # Extracting the text content from markdown split result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Semantic split\n",
    "semantic_list = process_semantic_split(plain_content)\n",
    "\n",
    "print(\"Number of semantic chunks:\"+str(len(semantic_list)))\n",
    "for split in semantic_list:\n",
    "    print(token_len(split))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write results\n",
    "with open('slit_results.txt', 'w') as file:\n",
    "    for item in semantic_list:\n",
    "        file.write(f\"------------\\n\")\n",
    "        file.write(f\"{item}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OPTIONAL EXPERIMENTS \n",
    "Experimenting with LLAMA - INDEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.embeddings.azure_openai import AzureOpenAIEmbedding\n",
    "from llama_index.readers.file import FlatReader\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "from llama_index.core.node_parser import MarkdownNodeParser\n",
    "from llama_index.core import SimpleDirectoryReader  \n",
    "from llama_index.core import Settings  \n",
    "from llama_index.core.node_parser import (  \n",
    "    SemanticSplitterNodeParser,  \n",
    ")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_model = AzureOpenAIEmbedding(\n",
    "    model=\"text-embedding-ada-002\",\n",
    "    deployment_name=os.environ[\"AZURE_OPENAI_EMBEDDING_MODEL\"],\n",
    "    api_key= os.environ[\"AZURE_OPENAI_API_KEY\"],\n",
    "    azure_endpoint=os.environ[\"AZURE_OPENAI_ENDPOINT\"],\n",
    "    api_version= \"2024-02-01\"\n",
    ")\n",
    "\n",
    "splitter = SemanticSplitterNodeParser(buffer_size=1, breakpoint_percentile_threshold=95, embed_model=embed_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normally would be expecting here a markdown document, but for the sake of the example we are using a plain text\n",
    "md_docs = FlatReader().load_data(Path(\"./sample_data/Tesla_Model_S.txt\"))\n",
    "parser = MarkdownNodeParser()\n",
    "nodes = parser.get_nodes_from_documents(md_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_nodes = splitter.get_nodes_from_documents(nodes)  \n",
    "\n",
    "print(len(split_nodes))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(split_nodes[6].get_content())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "C1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
